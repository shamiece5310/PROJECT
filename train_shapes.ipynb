{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "train_shapes.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shamiece5310/PROJECT/blob/master/train_shapes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y23VYOHo1OXR",
        "colab_type": "text"
      },
      "source": [
        "# Mask R-CNN - Train on Shapes Dataset\n",
        "\n",
        "\n",
        "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
        "\n",
        "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgCLpNDW4hXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "9f15064a-e482-4694-d1b0-d8981b5657fa"
      },
      "source": [
        "! git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mask_RCNN'...\n",
            "remote: Enumerating objects: 956, done.\u001b[K\n",
            "remote: Total 956 (delta 0), reused 0 (delta 0), pack-reused 956\u001b[K\n",
            "Receiving objects: 100% (956/956), 111.81 MiB | 34.95 MiB/s, done.\n",
            "Resolving deltas: 100% (571/571), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOD0JzAtHkrm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7d914351-f608-483a-892d-080d76158b12"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"../../\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading pretrained model to /content/Mask_RCNN/samples/mask_rcnn_coco.h5 ...\n",
            "... done downloading pretrained model!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh3Glp1xHvzZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "outputId": "18783838-662a-4069-b222-1eb6dbfb9e78"
      },
      "source": [
        "class ShapesConfig(Config):\n",
        "    \"\"\"Configuration for training on the toy shapes dataset.\n",
        "    Derives from the base Config class and overrides values specific\n",
        "    to the toy shapes dataset.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"shapes\"\n",
        "\n",
        "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
        "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 8\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
        "\n",
        "    # Use small images for faster training. Set the limits of the small side\n",
        "    # the large side, and that determines the image shape.\n",
        "    IMAGE_MIN_DIM = 128\n",
        "    IMAGE_MAX_DIM = 128\n",
        "\n",
        "    # Use smaller anchors because our image and objects are small\n",
        "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
        "\n",
        "    # Reduce training ROIs per image because the images are small and have\n",
        "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "\n",
        "    # Use a small epoch since the data is simple\n",
        "    STEPS_PER_EPOCH = 100\n",
        "\n",
        "    # use small validation steps since the epoch is small\n",
        "    VALIDATION_STEPS = 5\n",
        "    \n",
        "config = ShapesConfig()\n",
        "config.display()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     8\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 8\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  128\n",
            "IMAGE_META_SIZE                16\n",
            "IMAGE_MIN_DIM                  128\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [128 128   3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           shapes\n",
            "NUM_CLASSES                    4\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                100\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           32\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               5\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLx-X4JxH2i-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ax(rows=1, cols=1, size=8):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Change the default size attribute to control the size\n",
        "    of rendered images\n",
        "    \"\"\"\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h7-T3rfH8wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ShapesDataset(utils.Dataset):\n",
        "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
        "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
        "    The images are generated on the fly. No file access required.\n",
        "    \"\"\"\n",
        "\n",
        "    def load_shapes(self, count, height, width):\n",
        "        \"\"\"Generate the requested number of synthetic images.\n",
        "        count: number of images to generate.\n",
        "        height, width: the size of the generated images.\n",
        "        \"\"\"\n",
        "        # Add classes\n",
        "        self.add_class(\"shapes\", 1, \"square\")\n",
        "        self.add_class(\"shapes\", 2, \"circle\")\n",
        "        self.add_class(\"shapes\", 3, \"triangle\")\n",
        "\n",
        "        # Add images\n",
        "        # Generate random specifications of images (i.e. color and\n",
        "        # list of shapes sizes and locations). This is more compact than\n",
        "        # actual images. Images are generated on the fly in load_image().\n",
        "        for i in range(count):\n",
        "            bg_color, shapes = self.random_image(height, width)\n",
        "            self.add_image(\"shapes\", image_id=i, path=None,\n",
        "                           width=width, height=height,\n",
        "                           bg_color=bg_color, shapes=shapes)\n",
        "\n",
        "    def load_image(self, image_id):\n",
        "        \"\"\"Generate an image from the specs of the given image ID.\n",
        "        Typically this function loads the image from a file, but\n",
        "        in this case it generates the image on the fly from the\n",
        "        specs in image_info.\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
        "        image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
        "        image = image * bg_color.astype(np.uint8)\n",
        "        for shape, color, dims in info['shapes']:\n",
        "            image = self.draw_shape(image, shape, dims, color)\n",
        "        return image\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the shapes data of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"shapes\":\n",
        "            return info[\"shapes\"]\n",
        "        else:\n",
        "            super(self.__class__).image_reference(self, image_id)\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        shapes = info['shapes']\n",
        "        count = len(shapes)\n",
        "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
        "        for i, (shape, _, dims) in enumerate(info['shapes']):\n",
        "            mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(),\n",
        "                                                shape, dims, 1)\n",
        "        # Handle occlusions\n",
        "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
        "        for i in range(count-2, -1, -1):\n",
        "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
        "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
        "        # Map class names to class IDs.\n",
        "        class_ids = np.array([self.class_names.index(s[0]) for s in shapes])\n",
        "        return mask.astype(np.bool), class_ids.astype(np.int32)\n",
        "\n",
        "    def draw_shape(self, image, shape, dims, color):\n",
        "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
        "        # Get the center x, y and the size s\n",
        "        x, y, s = dims\n",
        "        if shape == 'square':\n",
        "            cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n",
        "        elif shape == \"circle\":\n",
        "            cv2.circle(image, (x, y), s, color, -1)\n",
        "        elif shape == \"triangle\":\n",
        "            points = np.array([[(x, y-s),\n",
        "                                (x-s/math.sin(math.radians(60)), y+s),\n",
        "                                (x+s/math.sin(math.radians(60)), y+s),\n",
        "                                ]], dtype=np.int32)\n",
        "            cv2.fillPoly(image, points, color)\n",
        "        return image\n",
        "\n",
        "    def random_shape(self, height, width):\n",
        "        \"\"\"Generates specifications of a random shape that lies within\n",
        "        the given height and width boundaries.\n",
        "        Returns a tuple of three valus:\n",
        "        * The shape name (square, circle, ...)\n",
        "        * Shape color: a tuple of 3 values, RGB.\n",
        "        * Shape dimensions: A tuple of values that define the shape size\n",
        "                            and location. Differs per shape type.\n",
        "        \"\"\"\n",
        "        # Shape\n",
        "        shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
        "        # Color\n",
        "        color = tuple([random.randint(0, 255) for _ in range(3)])\n",
        "        # Center x, y\n",
        "        buffer = 20\n",
        "        y = random.randint(buffer, height - buffer - 1)\n",
        "        x = random.randint(buffer, width - buffer - 1)\n",
        "        # Size\n",
        "        s = random.randint(buffer, height//4)\n",
        "        return shape, color, (x, y, s)\n",
        "\n",
        "    def random_image(self, height, width):\n",
        "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
        "        Returns the background color of the image and a list of shape\n",
        "        specifications that can be used to draw the image.\n",
        "        \"\"\"\n",
        "        # Pick random background color\n",
        "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
        "        # Generate a few random shapes and record their\n",
        "        # bounding boxes\n",
        "        shapes = []\n",
        "        boxes = []\n",
        "        N = random.randint(1, 4)\n",
        "        for _ in range(N):\n",
        "            shape, color, dims = self.random_shape(height, width)\n",
        "            shapes.append((shape, color, dims))\n",
        "            x, y, s = dims\n",
        "            boxes.append([y-s, x-s, y+s, x+s])\n",
        "        # Apply non-max suppression wit 0.3 threshold to avoid\n",
        "        # shapes covering each other\n",
        "        keep_ixs = utils.non_max_suppression(np.array(boxes), np.arange(N), 0.3)\n",
        "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
        "        return bg_color, shapes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1ijwGguIBah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training dataset\n",
        "dataset_train = ShapesDataset()\n",
        "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
        "dataset_train.prepare()\n",
        "\n",
        "# Validation dataset\n",
        "dataset_val = ShapesDataset()\n",
        "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
        "dataset_val.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgGsMvW9IFPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "83d760dd-f7d0-4160-8ff4-0b9f4da81b1a"
      },
      "source": [
        "# Load and display random samples\n",
        "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset_train.load_image(image_id)\n",
        "    mask, class_ids = dataset_train.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAACWCAYAAABO+G6lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1008x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAACWCAYAAABO+G6lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBAQAADBMQAAAAMMEBAAAMExAAAAAw/4X+KGTk9ZVkAgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1008x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAACWCAYAAABO+G6lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1008x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAACWCAYAAABO+G6lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAN0ECAAAoJsAAQAAdPt/WXum/8hbdZcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1008x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61hJ3nzPIK_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "0b186bc5-b410-4f37-bd2a-8b78cb0c40b6"
      },
      "source": [
        "\n",
        "\n",
        "# Create model in training mode\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/samples/Mask_RCNN/mrcnn/model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/samples/Mask_RCNN/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/samples/Mask_RCNN/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdwHu31HIPPI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "09ca3c7d-9e6c-445c-8012-53f4e09db3f2"
      },
      "source": [
        "# Which weights to start with?\n",
        "init_with = \"coco\"  # imagenet, coco, or last\n",
        "\n",
        "if init_with == \"imagenet\":\n",
        "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
        "elif init_with == \"coco\":\n",
        "    # Load weights trained on MS COCO, but skip layers that\n",
        "    # are different due to the different number of classes\n",
        "    # See README for instructions to download the COCO weights\n",
        "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "elif init_with == \"last\":\n",
        "    # Load the last model you trained and continue training\n",
        "    model.load_weights(model.find_last(), by_name=True)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77h_FVjPIVRq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ed21574-c7e1-449c-9eb2-9954534a375b"
      },
      "source": [
        "# Train the head branches\n",
        "# Passing layers=\"heads\" freezes all layers except the head\n",
        "# layers. You can also pass a regular expression to select\n",
        "# which layers to train by name pattern.\n",
        "model.train(dataset_train, dataset_val, \n",
        "            learning_rate=config.LEARNING_RATE, \n",
        "            epochs=1, \n",
        "            layers='heads')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /content/Mask_RCNN/samples/logs/shapes20191125T1023/mask_rcnn_shapes_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 102s 1s/step - loss: 1.8684 - rpn_class_loss: 0.0324 - rpn_bbox_loss: 0.6533 - mrcnn_class_loss: 0.3660 - mrcnn_bbox_loss: 0.4212 - mrcnn_mask_loss: 0.3955 - val_loss: 0.8647 - val_rpn_class_loss: 0.0125 - val_rpn_bbox_loss: 0.3918 - val_mrcnn_class_loss: 0.1468 - val_mrcnn_bbox_loss: 0.1926 - val_mrcnn_mask_loss: 0.1209\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqXFRbcFJDWC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5AzDBlxIkpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a3f30c0e-7e73-4ab4-8fa3-fbae3cd35901"
      },
      "source": [
        "# Fine tune all layers\n",
        "# Passing layers=\"all\" trains all layers. You can also \n",
        "# pass a regular expression to select which layers to\n",
        "# train by name pattern.\n",
        "model.train(dataset_train, dataset_val, \n",
        "            learning_rate=config.LEARNING_RATE / 10,\n",
        "            epochs=2, \n",
        "            layers=\"all\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 1. LR=0.0001\n",
            "\n",
            "Checkpoint Path: /content/Mask_RCNN/samples/logs/shapes20191125T1023/mask_rcnn_shapes_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "conv1                  (Conv2D)\n",
            "bn_conv1               (BatchNorm)\n",
            "res2a_branch2a         (Conv2D)\n",
            "bn2a_branch2a          (BatchNorm)\n",
            "res2a_branch2b         (Conv2D)\n",
            "bn2a_branch2b          (BatchNorm)\n",
            "res2a_branch2c         (Conv2D)\n",
            "res2a_branch1          (Conv2D)\n",
            "bn2a_branch2c          (BatchNorm)\n",
            "bn2a_branch1           (BatchNorm)\n",
            "res2b_branch2a         (Conv2D)\n",
            "bn2b_branch2a          (BatchNorm)\n",
            "res2b_branch2b         (Conv2D)\n",
            "bn2b_branch2b          (BatchNorm)\n",
            "res2b_branch2c         (Conv2D)\n",
            "bn2b_branch2c          (BatchNorm)\n",
            "res2c_branch2a         (Conv2D)\n",
            "bn2c_branch2a          (BatchNorm)\n",
            "res2c_branch2b         (Conv2D)\n",
            "bn2c_branch2b          (BatchNorm)\n",
            "res2c_branch2c         (Conv2D)\n",
            "bn2c_branch2c          (BatchNorm)\n",
            "res3a_branch2a         (Conv2D)\n",
            "bn3a_branch2a          (BatchNorm)\n",
            "res3a_branch2b         (Conv2D)\n",
            "bn3a_branch2b          (BatchNorm)\n",
            "res3a_branch2c         (Conv2D)\n",
            "res3a_branch1          (Conv2D)\n",
            "bn3a_branch2c          (BatchNorm)\n",
            "bn3a_branch1           (BatchNorm)\n",
            "res3b_branch2a         (Conv2D)\n",
            "bn3b_branch2a          (BatchNorm)\n",
            "res3b_branch2b         (Conv2D)\n",
            "bn3b_branch2b          (BatchNorm)\n",
            "res3b_branch2c         (Conv2D)\n",
            "bn3b_branch2c          (BatchNorm)\n",
            "res3c_branch2a         (Conv2D)\n",
            "bn3c_branch2a          (BatchNorm)\n",
            "res3c_branch2b         (Conv2D)\n",
            "bn3c_branch2b          (BatchNorm)\n",
            "res3c_branch2c         (Conv2D)\n",
            "bn3c_branch2c          (BatchNorm)\n",
            "res3d_branch2a         (Conv2D)\n",
            "bn3d_branch2a          (BatchNorm)\n",
            "res3d_branch2b         (Conv2D)\n",
            "bn3d_branch2b          (BatchNorm)\n",
            "res3d_branch2c         (Conv2D)\n",
            "bn3d_branch2c          (BatchNorm)\n",
            "res4a_branch2a         (Conv2D)\n",
            "bn4a_branch2a          (BatchNorm)\n",
            "res4a_branch2b         (Conv2D)\n",
            "bn4a_branch2b          (BatchNorm)\n",
            "res4a_branch2c         (Conv2D)\n",
            "res4a_branch1          (Conv2D)\n",
            "bn4a_branch2c          (BatchNorm)\n",
            "bn4a_branch1           (BatchNorm)\n",
            "res4b_branch2a         (Conv2D)\n",
            "bn4b_branch2a          (BatchNorm)\n",
            "res4b_branch2b         (Conv2D)\n",
            "bn4b_branch2b          (BatchNorm)\n",
            "res4b_branch2c         (Conv2D)\n",
            "bn4b_branch2c          (BatchNorm)\n",
            "res4c_branch2a         (Conv2D)\n",
            "bn4c_branch2a          (BatchNorm)\n",
            "res4c_branch2b         (Conv2D)\n",
            "bn4c_branch2b          (BatchNorm)\n",
            "res4c_branch2c         (Conv2D)\n",
            "bn4c_branch2c          (BatchNorm)\n",
            "res4d_branch2a         (Conv2D)\n",
            "bn4d_branch2a          (BatchNorm)\n",
            "res4d_branch2b         (Conv2D)\n",
            "bn4d_branch2b          (BatchNorm)\n",
            "res4d_branch2c         (Conv2D)\n",
            "bn4d_branch2c          (BatchNorm)\n",
            "res4e_branch2a         (Conv2D)\n",
            "bn4e_branch2a          (BatchNorm)\n",
            "res4e_branch2b         (Conv2D)\n",
            "bn4e_branch2b          (BatchNorm)\n",
            "res4e_branch2c         (Conv2D)\n",
            "bn4e_branch2c          (BatchNorm)\n",
            "res4f_branch2a         (Conv2D)\n",
            "bn4f_branch2a          (BatchNorm)\n",
            "res4f_branch2b         (Conv2D)\n",
            "bn4f_branch2b          (BatchNorm)\n",
            "res4f_branch2c         (Conv2D)\n",
            "bn4f_branch2c          (BatchNorm)\n",
            "res4g_branch2a         (Conv2D)\n",
            "bn4g_branch2a          (BatchNorm)\n",
            "res4g_branch2b         (Conv2D)\n",
            "bn4g_branch2b          (BatchNorm)\n",
            "res4g_branch2c         (Conv2D)\n",
            "bn4g_branch2c          (BatchNorm)\n",
            "res4h_branch2a         (Conv2D)\n",
            "bn4h_branch2a          (BatchNorm)\n",
            "res4h_branch2b         (Conv2D)\n",
            "bn4h_branch2b          (BatchNorm)\n",
            "res4h_branch2c         (Conv2D)\n",
            "bn4h_branch2c          (BatchNorm)\n",
            "res4i_branch2a         (Conv2D)\n",
            "bn4i_branch2a          (BatchNorm)\n",
            "res4i_branch2b         (Conv2D)\n",
            "bn4i_branch2b          (BatchNorm)\n",
            "res4i_branch2c         (Conv2D)\n",
            "bn4i_branch2c          (BatchNorm)\n",
            "res4j_branch2a         (Conv2D)\n",
            "bn4j_branch2a          (BatchNorm)\n",
            "res4j_branch2b         (Conv2D)\n",
            "bn4j_branch2b          (BatchNorm)\n",
            "res4j_branch2c         (Conv2D)\n",
            "bn4j_branch2c          (BatchNorm)\n",
            "res4k_branch2a         (Conv2D)\n",
            "bn4k_branch2a          (BatchNorm)\n",
            "res4k_branch2b         (Conv2D)\n",
            "bn4k_branch2b          (BatchNorm)\n",
            "res4k_branch2c         (Conv2D)\n",
            "bn4k_branch2c          (BatchNorm)\n",
            "res4l_branch2a         (Conv2D)\n",
            "bn4l_branch2a          (BatchNorm)\n",
            "res4l_branch2b         (Conv2D)\n",
            "bn4l_branch2b          (BatchNorm)\n",
            "res4l_branch2c         (Conv2D)\n",
            "bn4l_branch2c          (BatchNorm)\n",
            "res4m_branch2a         (Conv2D)\n",
            "bn4m_branch2a          (BatchNorm)\n",
            "res4m_branch2b         (Conv2D)\n",
            "bn4m_branch2b          (BatchNorm)\n",
            "res4m_branch2c         (Conv2D)\n",
            "bn4m_branch2c          (BatchNorm)\n",
            "res4n_branch2a         (Conv2D)\n",
            "bn4n_branch2a          (BatchNorm)\n",
            "res4n_branch2b         (Conv2D)\n",
            "bn4n_branch2b          (BatchNorm)\n",
            "res4n_branch2c         (Conv2D)\n",
            "bn4n_branch2c          (BatchNorm)\n",
            "res4o_branch2a         (Conv2D)\n",
            "bn4o_branch2a          (BatchNorm)\n",
            "res4o_branch2b         (Conv2D)\n",
            "bn4o_branch2b          (BatchNorm)\n",
            "res4o_branch2c         (Conv2D)\n",
            "bn4o_branch2c          (BatchNorm)\n",
            "res4p_branch2a         (Conv2D)\n",
            "bn4p_branch2a          (BatchNorm)\n",
            "res4p_branch2b         (Conv2D)\n",
            "bn4p_branch2b          (BatchNorm)\n",
            "res4p_branch2c         (Conv2D)\n",
            "bn4p_branch2c          (BatchNorm)\n",
            "res4q_branch2a         (Conv2D)\n",
            "bn4q_branch2a          (BatchNorm)\n",
            "res4q_branch2b         (Conv2D)\n",
            "bn4q_branch2b          (BatchNorm)\n",
            "res4q_branch2c         (Conv2D)\n",
            "bn4q_branch2c          (BatchNorm)\n",
            "res4r_branch2a         (Conv2D)\n",
            "bn4r_branch2a          (BatchNorm)\n",
            "res4r_branch2b         (Conv2D)\n",
            "bn4r_branch2b          (BatchNorm)\n",
            "res4r_branch2c         (Conv2D)\n",
            "bn4r_branch2c          (BatchNorm)\n",
            "res4s_branch2a         (Conv2D)\n",
            "bn4s_branch2a          (BatchNorm)\n",
            "res4s_branch2b         (Conv2D)\n",
            "bn4s_branch2b          (BatchNorm)\n",
            "res4s_branch2c         (Conv2D)\n",
            "bn4s_branch2c          (BatchNorm)\n",
            "res4t_branch2a         (Conv2D)\n",
            "bn4t_branch2a          (BatchNorm)\n",
            "res4t_branch2b         (Conv2D)\n",
            "bn4t_branch2b          (BatchNorm)\n",
            "res4t_branch2c         (Conv2D)\n",
            "bn4t_branch2c          (BatchNorm)\n",
            "res4u_branch2a         (Conv2D)\n",
            "bn4u_branch2a          (BatchNorm)\n",
            "res4u_branch2b         (Conv2D)\n",
            "bn4u_branch2b          (BatchNorm)\n",
            "res4u_branch2c         (Conv2D)\n",
            "bn4u_branch2c          (BatchNorm)\n",
            "res4v_branch2a         (Conv2D)\n",
            "bn4v_branch2a          (BatchNorm)\n",
            "res4v_branch2b         (Conv2D)\n",
            "bn4v_branch2b          (BatchNorm)\n",
            "res4v_branch2c         (Conv2D)\n",
            "bn4v_branch2c          (BatchNorm)\n",
            "res4w_branch2a         (Conv2D)\n",
            "bn4w_branch2a          (BatchNorm)\n",
            "res4w_branch2b         (Conv2D)\n",
            "bn4w_branch2b          (BatchNorm)\n",
            "res4w_branch2c         (Conv2D)\n",
            "bn4w_branch2c          (BatchNorm)\n",
            "res5a_branch2a         (Conv2D)\n",
            "bn5a_branch2a          (BatchNorm)\n",
            "res5a_branch2b         (Conv2D)\n",
            "bn5a_branch2b          (BatchNorm)\n",
            "res5a_branch2c         (Conv2D)\n",
            "res5a_branch1          (Conv2D)\n",
            "bn5a_branch2c          (BatchNorm)\n",
            "bn5a_branch1           (BatchNorm)\n",
            "res5b_branch2a         (Conv2D)\n",
            "bn5b_branch2a          (BatchNorm)\n",
            "res5b_branch2b         (Conv2D)\n",
            "bn5b_branch2b          (BatchNorm)\n",
            "res5b_branch2c         (Conv2D)\n",
            "bn5b_branch2c          (BatchNorm)\n",
            "res5c_branch2a         (Conv2D)\n",
            "bn5c_branch2a          (BatchNorm)\n",
            "res5c_branch2b         (Conv2D)\n",
            "bn5c_branch2b          (BatchNorm)\n",
            "res5c_branch2c         (Conv2D)\n",
            "bn5c_branch2c          (BatchNorm)\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/2\n",
            "100/100 [==============================] - 145s 1s/step - loss: 0.8724 - rpn_class_loss: 0.0165 - rpn_bbox_loss: 0.4221 - mrcnn_class_loss: 0.1384 - mrcnn_bbox_loss: 0.1463 - mrcnn_mask_loss: 0.1490 - val_loss: 0.7121 - val_rpn_class_loss: 0.0120 - val_rpn_bbox_loss: 0.3810 - val_mrcnn_class_loss: 0.0762 - val_mrcnn_bbox_loss: 0.1272 - val_mrcnn_mask_loss: 0.1157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnevPiiFIr3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save weights\n",
        "# Typically not needed because callbacks save after every epoch\n",
        "# Uncomment to save manually\n",
        "# model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
        "# model.keras_model.save_weights(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8dygVYrI0al",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "70523c15-6162-4717-c227-2bf0b6b3a3f6"
      },
      "source": [
        "class InferenceConfig(ShapesConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
        "model_path = model.find_last()\n",
        "\n",
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/Mask_RCNN/samples/Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/samples/Mask_RCNN/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/samples/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "Loading weights from  /content/Mask_RCNN/samples/logs/shapes20191125T1023/mask_rcnn_shapes_0002.h5\n",
            "Re-starting from epoch 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TB4KzrPI8MC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "9ffadc24-1450-4cb4-b324-6006e861a445"
      },
      "source": [
        "# Test on a random image\n",
        "image_id = random.choice(dataset_val.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_val, inference_config, \n",
        "                           image_id, use_mini_mask=False)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original_image           shape: (128, 128, 3)         min:   71.00000  max:  147.00000  uint8\n",
            "image_meta               shape: (16,)                 min:    0.00000  max:  128.00000  int64\n",
            "gt_class_id              shape: (1,)                  min:    2.00000  max:    2.00000  int32\n",
            "gt_bbox                  shape: (1, 4)                min:   62.00000  max:  128.00000  int32\n",
            "gt_mask                  shape: (128, 128, 1)         min:    0.00000  max:    1.00000  bool\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcEAAAHBCAYAAAARuwDoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRQQBAGYRQQCAWf8ffaodMqyBjmEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBptMyB2JGn7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "69a1001e-0c79-4cb1-a49d-fd2cb3cc9252"
      },
      "source": [
        "\n",
        "\n",
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_val.class_names, r['scores'], ax=get_ax())\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing 1 images\n",
            "image                    shape: (128, 128, 3)         min:   71.00000  max:  147.00000  uint8\n",
            "molded_images            shape: (1, 128, 128, 3)      min:  -45.80000  max:   34.10000  float64\n",
            "image_metas              shape: (1, 16)               min:    0.00000  max:  128.00000  int64\n",
            "anchors                  shape: (1, 4092, 4)          min:   -0.71267  max:    1.20874  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcEAAAHBCAYAAAARuwDoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRBAAYNb/B6lhuTGBFvAwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bREJJAQ7JJsk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "74c04a3e-0f35-447c-f0f7-0414eab8522d"
      },
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "# Running on 10 images. Increase for better accuracy.\n",
        "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_val, inference_config,\n",
        "                               image_id, use_mini_mask=False)\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "    # Run object detection\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "    \n",
        "print(\"mAP: \", np.mean(APs))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mAP:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}